"""
ç”µåŠ¨æ±½è½¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿ - RAGæœåŠ¡
"""
import os
from typing import List, Dict, Any, Optional
from pathlib import Path
from loguru import logger

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory

from app.core.config import settings

class EVRAGService:
    """ç”µåŠ¨æ±½è½¦é¢†åŸŸRAGæœåŠ¡"""
    
    def __init__(self):
        self.vector_store = None
        self.qa_chain = None
        self.initialized = False
        self.ev_keywords = settings.DOMAIN_KEYWORDS
        
    def initialize(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        try:
            logger.info("ğŸš€ åˆå§‹åŒ–ç”µåŠ¨æ±½è½¦RAGç³»ç»Ÿ...")
            
            # 1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            embeddings = OllamaEmbeddings(
                base_url=settings.OLLAMA_BASE_URL,
                model=settings.OLLAMA_EMBEDDING_MODEL
            )
            
            # 2. åˆå§‹åŒ–å‘é‡å­˜å‚¨
            vector_store_path = settings.VECTOR_DB_DIR / "ev_knowledge"
            self.vector_store = Chroma(
                persist_directory=str(vector_store_path),
                embedding_function=embeddings,
                collection_name="ev_knowledge_base"
            )
            
            # 3. åˆå§‹åŒ–LLM
            llm = Ollama(
                base_url=settings.OLLAMA_BASE_URL,
                model=settings.OLLAMA_MODEL,
                temperature=0.1,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´å‡†ç¡®çš„å›ç­”
                num_predict=512  # é™åˆ¶ç”Ÿæˆé•¿åº¦
            )
            
            # 4. åˆ›å»ºç”µåŠ¨æ±½è½¦é¢†åŸŸç‰¹å®šçš„æç¤ºæ¨¡æ¿
            prompt_template = PromptTemplate(
                template="""ä½ æ˜¯ä¸€ä¸ªç”µåŠ¨æ±½è½¦é¢†åŸŸçš„ä¸“å®¶åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

é—®é¢˜: {question}

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å›ç­”:
1. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸­åŒ…å«ç­”æ¡ˆï¼Œè¯·åŸºäºä¸Šä¸‹æ–‡å‡†ç¡®å›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·åŸºäºä½ çš„ç”µåŠ¨æ±½è½¦é¢†åŸŸçŸ¥è¯†å›ç­”
3. å›ç­”è¦ä¸“ä¸šã€å‡†ç¡®ã€ç®€æ´
4. å¦‚æœæ¶‰åŠæŠ€æœ¯å‚æ•°ï¼Œè¯·æä¾›å…·ä½“æ•°å€¼
5. å¯¹äºä¸ç¡®å®šçš„ä¿¡æ¯ï¼Œè¯·è¯´æ˜"æ ¹æ®ç°æœ‰ä¿¡æ¯æ— æ³•ç¡®å®š"

ç”µåŠ¨æ±½è½¦é¢†åŸŸå…³é”®è¯: {keywords}

è¯·ç”¨ä¸­æ–‡å›ç­”:""",
                input_variables=["context", "question", "keywords"]
            )
            
            # 5. åˆ›å»ºæ£€ç´¢QAé“¾
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=self.vector_store.as_retriever(
                    search_kwargs={"k": settings.SIMILARITY_TOP_K}
                ),
                chain_type_kwargs={
                    "prompt": prompt_template,
                    "verbose": True
                },
                return_source_documents=True
            )
            
            # 6. åˆå§‹åŒ–å¯¹è¯è®°å¿†
            self.memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
            
            self.initialized = True
            logger.info("âœ… ç”µåŠ¨æ±½è½¦RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def is_initialized(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–"""
        return self.initialized
    
    def add_documents(self, documents: List[str], metadata: List[Dict] = None):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        if not self.initialized:
            self.initialize()
        
        try:
            # æ–‡æœ¬åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=settings.CHUNK_SIZE,
                chunk_overlap=settings.CHUNK_OVERLAP,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", "ã€", " "]
            )
            
            chunks = text_splitter.create_documents(documents, metadata)
            
            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            self.vector_store.add_documents(chunks)
            self.vector_store.persist()
            
            logger.info(f"âœ… å·²æ·»åŠ  {len(chunks)} ä¸ªæ–‡æ¡£å—åˆ°çŸ¥è¯†åº“")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def ask_question(self, question: str) -> Dict[str, Any]:
        """æé—®é—®é¢˜"""
        if not self.initialized:
            self.initialize()
        
        try:
            # å¢å¼ºé—®é¢˜ï¼ˆæ·»åŠ ç”µåŠ¨æ±½è½¦é¢†åŸŸä¸Šä¸‹æ–‡ï¼‰
            enhanced_question = self._enhance_question(question)
            
            # æ‰§è¡Œé—®ç­”
            result = self.qa_chain({
                "query": enhanced_question,
                "keywords": ", ".join(self.ev_keywords)
            })
            
            # æå–æºæ–‡æ¡£ä¿¡æ¯
            sources = []
            if "source_documents" in result:
                for doc in result["source_documents"]:
                    source_info = {
                        "content": doc.page_content[:200] + "...",
                        "metadata": doc.metadata
                    }
                    sources.append(source_info)
            
            # æ›´æ–°å¯¹è¯è®°å¿†
            self.memory.save_context(
                {"input": question},
                {"output": result["result"]}
            )
            
            return {
                "answer": result["result"],
                "sources": sources,
                "question": question,
                "enhanced_question": enhanced_question,
                "domain": "electric_vehicles"
            }
            
        except Exception as e:
            logger.error(f"âŒ é—®ç­”å¤±è´¥: {e}")
            return {
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "sources": [],
                "question": question,
                "error": str(e)
            }
    
    def _enhance_question(self, question: str) -> str:
        """å¢å¼ºé—®é¢˜ - æ·»åŠ ç”µåŠ¨æ±½è½¦é¢†åŸŸä¸Šä¸‹æ–‡"""
        enhanced = question
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”µåŠ¨æ±½è½¦å…³é”®è¯
        has_ev_keyword = any(keyword in question for keyword in self.ev_keywords)
        
        if not has_ev_keyword:
            # å¦‚æœä¸æ˜¯æ˜æ˜¾çš„ç”µåŠ¨æ±½è½¦é—®é¢˜ï¼Œæ·»åŠ é¢†åŸŸæç¤º
            enhanced = f"å…³äºç”µåŠ¨æ±½è½¦é¢†åŸŸçš„: {question}"
        
        return enhanced
    
    def search_similar(self, query: str, k: int = 5) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼å†…å®¹"""
        if not self.initialized:
            self.initialize()
        
        try:
            results = self.vector_store.similarity_search_with_score(query, k=k)
            
            formatted_results = []
            for doc, score in results:
                formatted_results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "score": float(score)
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_knowledge_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        if not self.initialized:
            self.initialize()
        
        try:
            # è·å–é›†åˆä¿¡æ¯
            collection = self.vector_store._collection
            count = collection.count() if collection else 0
            
            return {
                "document_count": count,
                "domain": settings.DOMAIN,
                "keywords": self.ev_keywords,
                "model": settings.OLLAMA_MODEL,
                "vector_db": "Chroma",
                "status": "active" if count > 0 else "empty"
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "document_count": 0,
                "domain": settings.DOMAIN,
                "status": "error",
                "error": str(e)
            }
    
    def clear_knowledge_base(self) -> bool:
        """æ¸…ç©ºçŸ¥è¯†åº“"""
        try:
            if self.vector_store:
                self.vector_store.delete_collection()
                self.vector_store = None
            
            # é‡æ–°åˆå§‹åŒ–
            self.initialized = False
            self.initialize()
            
            logger.info("âœ… çŸ¥è¯†åº“å·²æ¸…ç©º")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return False

# å…¨å±€RAGæœåŠ¡å®ä¾‹
rag_service = EVRAGService()